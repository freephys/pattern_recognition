{
 "metadata": {
  "name": "",
  "signature": "sha256:9693a83b3b29faeff662a89f6745f235b732d5b2d33c77371bb3b9b27f9b3b60"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b> Pattern Classification \n",
      "\n",
      "V. Mirjalili \n",
      "04-04-2014 </b>\n",
      "\n",
      "<h1>Bayes Classification</h1>\n",
      "\n",
      "<h3>Description of input data </h3>\n",
      "\n",
      "Input data contains 2 features $\\bar{x} =\\left\\{x_1, x_2\\right\\}$. Each sample belongs to one of the three classes: $\\left\\{w_1, w_2, w_3\\right\\}$.\n",
      "Overall, there are 1500 samples. \n",
      "First we will read the data into a numpy 2D array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "data = np.loadtxt('input_data.txt')\n",
      "print(data.shape)\n",
      "ntot = len(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500, 3)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4> Constructing Training and test sets</h4>\n",
      "\n",
      "Next, we create a training subset that contains 70% of all data (randomly selected), \n",
      "and assign the rest of data to a test set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#train_inx = (np.random.sample(100)*100).astype(int)\n",
      "train_index = np.random.choice(np.arange(ntot), size=0.7*ntot, replace=False)\n",
      "print(len(train_index))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1050\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train = data[train_index,0:]\n",
      "#print(X_train[0:6])\n",
      "X_test = data[list(set(np.arange(ntot)) - set(train_index)),:]\n",
      "print(len(X_train), len(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1050, 450)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h4>Bayes Decision Rule Given Class Conditional Densities (PDFs)</h4>\n",
      "\n",
      "If we assume that the class conditional densities are as below:\n",
      "\n",
      "$ p(\\underline{x} | w_1) \\sim N([0,0]^t, 4I) $\n",
      "\n",
      "$ p(\\bar{x} | w_2) \\sim N([10,0]^t, 4I) $\n",
      "\n",
      "$ p(\\bar{x} | w_3) \\sim N([5,5]^t, 5I) $\n",
      "\n",
      "Having equal priors, $ P(w_1) = P(w_2) = P(w_3) $, and Bayes formula for posterior probability $ P(w_i | \\bar{x}) = \\frac{p(\\bar{x}|w_i) P(w_i)}{P(\\bar{x})} $, then we set up the discriminant functions $g_i = \\ln P(w_i | \\bar{x})$ in which equal priors and other constant terms can be omitted to reach:\n",
      "\n",
      "$ g_i = -\\frac{1}{2}(x-\\mu_i)^t \\Sigma_i^{-1} (x-\\mu_i) -\\frac{1}{2} |\\Sigma_i| \\Longrightarrow -(x-\\mu_i)^t \\Sigma_i^{-1} (x-\\mu_i) - |\\Sigma_i|$\n",
      "\n",
      "\n",
      "Therefore, each pattern $x$ is classified to class $w_i$ whose discriminant function $g_i$ is maximum.\n",
      "\n",
      "Note that if we muliply it by $-1$, then"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}